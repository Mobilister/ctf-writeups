 
 Solution: 
 I used the following model astronomer/astronomer/Llama-3-8B-Instruct-GPTQ-8-Bit at huggingfaces 
 Extract the tokens from the model: 
 `` python3 model.py astronomer/Llama-3-8B-Instruct-GPTQ-8-Bit 
 The tokenizer is the same for chatGPT tough
 
 
